{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pandas as pd\n",
    "\n",
    "from llama_index.core.schema import TextNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "embed = OpenAIEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path: str) -> List[TextNode]:\n",
    "    \"\"\"\n",
    "    Read the data from a file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The file path.\n",
    "\n",
    "    Returns:\n",
    "        List[TextNode]: The list of text nodes.\n",
    "    \"\"\"\n",
    "    # Read the data\n",
    "    bookings_df = pd.read_parquet(file_path)\n",
    "\n",
    "    # Construct LlamaIndex TextNodes\n",
    "    nodes = []\n",
    "    for _, row in bookings_df.iterrows():\n",
    "        # Convert the reviews column to a list of dictionaries\n",
    "        for review in row[\"reviews\"]:\n",
    "            nodes.append(\n",
    "                TextNode(\n",
    "                    text=f\"Hotel: {row['hotel_name']}, reviewed by User: {review['username']} | Review Title: {review['review_title']} | Review: {review.get('en_full_review', 'No review text available')}\",\n",
    "                    # metadata={\n",
    "                    #     \"hotel\": {\"name\": row['hotel_name']},\n",
    "                    #     \"user\": {\n",
    "                    #         \"username\": review[\"username\"],\n",
    "                    #         \"country\": review[\"user_country\"],\n",
    "                    #     },\n",
    "                    #     \"review\": {\n",
    "                    #         \"title\": review[\"review_title\"],\n",
    "                    #         \"content\": review.get(\n",
    "                    #             \"en_full_review\", \"No review text available\"\n",
    "                    #         ),\n",
    "                    #         \"rating\": review[\"rating\"],\n",
    "                    #         \"post_date\": review[\"review_post_date\"],\n",
    "                    #         \"stay_duration\": review[\"stay_duration\"],\n",
    "                    #         \"stay_type\": review[\"stay_type\"],\n",
    "                    #     },\n",
    "                    # },\n",
    "                )\n",
    "            )\n",
    "            # Only use the first review for each hotel\n",
    "            break\n",
    "\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = read_data(\"data/bookings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from collections.abc import Callable\n",
    "from typing import Any\n",
    "from typing import List\n",
    "from typing import Optional\n",
    "from typing import Union\n",
    "\n",
    "import nest_asyncio\n",
    "from llama_index.core.async_utils import run_jobs\n",
    "from llama_index.core.graph_stores.types import EntityNode\n",
    "from llama_index.core.graph_stores.types import KG_NODES_KEY\n",
    "from llama_index.core.graph_stores.types import KG_RELATIONS_KEY\n",
    "from llama_index.core.graph_stores.types import Relation\n",
    "from llama_index.core.indices.property_graph import default_parse_triplets_fn\n",
    "from llama_index.core.llms import LLM\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.prompts.default_prompts import DEFAULT_KG_TRIPLET_EXTRACT_PROMPT\n",
    "from llama_index.core.schema import BaseNode\n",
    "from llama_index.core.schema import TransformComponent\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "class RecommendationGraphExtractor(TransformComponent):\n",
    "    \"\"\"\n",
    "    Extract triples from a graph.\n",
    "    Uses an LLM and a simple prompt + output parsing to extract paths (i.e. triples) and entity, relation descriptions from text.\n",
    "    \"\"\"\n",
    "    \n",
    "    llm: LLM\n",
    "    extract_prompt: PromptTemplate\n",
    "    parse_fn: Callable\n",
    "    num_workers: int\n",
    "    max_paths_per_chunk: int\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm: Optional[LLM] = None,\n",
    "        extract_prompt: Optional[Union[str, PromptTemplate]] = None,\n",
    "        parse_fn: Optional[Callable] = default_parse_triplets_fn,\n",
    "        max_paths_per_chunk: int = 100,\n",
    "        num_workers: int = 4,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the GraphRAGExtractor.\n",
    "\n",
    "        Args:\n",
    "            llm (LLM): The language model to use.\n",
    "            extract_prompt (Union[str, PromptTemplate]): The prompt to use for extracting triples.\n",
    "            parse_fn (callable): A function to parse the output of the language model.\n",
    "            num_workers (int): The number of workers to use for parallel processing.\n",
    "            max_paths_per_chunk (int): The maximum number of paths to extract per chunk.\n",
    "        \"\"\"\n",
    "        from llama_index.core import Settings\n",
    "\n",
    "        if isinstance(extract_prompt, str):\n",
    "            extract_prompt = PromptTemplate(template=extract_prompt)\n",
    "\n",
    "        super().__init__(\n",
    "            llm=llm or Settings.llm,\n",
    "            extract_prompt=extract_prompt or DEFAULT_KG_TRIPLET_EXTRACT_PROMPT,\n",
    "            parse_fn=parse_fn,\n",
    "            num_workers=num_workers,\n",
    "            max_paths_per_chunk=max_paths_per_chunk,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def class_name(cls) -> str:\n",
    "        return \"GraphExtractor\"\n",
    "\n",
    "    def __call__(\n",
    "        self, nodes: List[BaseNode], show_progress: bool = False, **kwargs: Any\n",
    "    ) -> List[BaseNode]:\n",
    "        \"\"\"\n",
    "        Extract triples from a list of nodes.\n",
    "\n",
    "        Args:\n",
    "            nodes (List[BaseNode]): The nodes to extract triples from.\n",
    "            show_progress (bool): Whether to show the progress of the extraction.\n",
    "\n",
    "        Returns:\n",
    "            List[BaseNode]: The nodes with extracted triples.\n",
    "        \"\"\"\n",
    "        return asyncio.run(\n",
    "            self.acall(nodes=nodes, show_progress=show_progress, **kwargs)\n",
    "        )\n",
    "\n",
    "    async def _aextract(self, node: BaseNode) -> BaseNode:\n",
    "        \"\"\"\n",
    "        Extract triples from a node asynchronously.\n",
    "\n",
    "        Args:\n",
    "            node (BaseNode): The node to extract triples from.\n",
    "\n",
    "        Returns:\n",
    "            BaseNode: The node with extracted triples.\n",
    "        \"\"\"\n",
    "        assert hasattr(node, \"text\")\n",
    "\n",
    "        text = node.get_content(metadata_mode=\"llm\")\n",
    "        try:\n",
    "            llm_reponse = await self.llm.apredict(\n",
    "                prompt=self.extract_prompt,\n",
    "                text=text,\n",
    "                max_knowledge_triplets=self.max_paths_per_chunk,\n",
    "            )\n",
    "            entities, relationships = self.parse_fn(llm_reponse)\n",
    "        except ValueError:\n",
    "            entities, relationships = [], []\n",
    "\n",
    "        existing_nodes = node.metadata.pop(KG_NODES_KEY, [])\n",
    "        entity_metadata = node.metadata.copy()\n",
    "        for entity, entity_type, description, attributes in entities:\n",
    "            entity_metadata = {\n",
    "                \"description\": description,\n",
    "                \"attributes\": attributes,\n",
    "                \"type\": entity_type,\n",
    "                \"embedding_key\": f\"{entity_type}_{entity}\",\n",
    "            }\n",
    "            entity_node = EntityNode(\n",
    "                name=entity, label=entity_type, properties=entity_metadata\n",
    "            )\n",
    "            existing_nodes.append(entity_node)\n",
    "\n",
    "        existing_relations = node.metadata.pop(KG_RELATIONS_KEY, [])\n",
    "        for src, tgt, rel, strength, desc, features in relationships:\n",
    "            relation_metadata = {\n",
    "                \"description\": desc,\n",
    "                \"strength\": float(strength),\n",
    "                \"features\": features,\n",
    "                \"source_type\": next((e[1] for e in entities if e[0] == src), None),\n",
    "                \"target_type\": next((e[1] for e in entities if e[0] == tgt), None),\n",
    "            }\n",
    "            relation = Relation(\n",
    "                label=rel, source_id=src, target_id=tgt, properties=relation_metadata\n",
    "            )\n",
    "            existing_relations.append(relation)\n",
    "\n",
    "        node.metadata[KG_NODES_KEY] = existing_nodes\n",
    "        node.metadata[KG_RELATIONS_KEY] = existing_relations\n",
    "        return node\n",
    "\n",
    "    async def acall(\n",
    "        self, nodes: List[BaseNode], show_progress: bool = False, **kwargs: Any\n",
    "    ) -> List[BaseNode]:\n",
    "        \"\"\"\n",
    "        Extract triples from a list of nodes asynchronously.\n",
    "\n",
    "        Args:\n",
    "            nodes (List[BaseNode]): The nodes to extract triples from.\n",
    "            show_progress (bool): Whether to show the progress of the extraction.\n",
    "\n",
    "        Returns:\n",
    "            List[BaseNode]: The nodes with extracted triples.\n",
    "        \"\"\"\n",
    "        jobs = []\n",
    "        for node in nodes:\n",
    "            jobs.append(self._aextract(node=node))\n",
    "\n",
    "        return await run_jobs(\n",
    "            jobs,\n",
    "            workers=self.num_workers,\n",
    "            show_progress=show_progress,\n",
    "            desc=\"Extracting paths from text\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "from typing import Any\n",
    "from typing import Dict\n",
    "from typing import Tuple\n",
    "\n",
    "import networkx as nx\n",
    "from graspologic.partition import hierarchical_leiden\n",
    "from graspologic.partition import HierarchicalClusters\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore\n",
    "\n",
    "\n",
    "class RecommendationGraphStore(Neo4jPropertyGraphStore):\n",
    "    \"\"\"\n",
    "    Extended graph store with recommendation-specific functionality.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.community_summaries = {}\n",
    "        self.entity_info = None\n",
    "        self.max_cluster_size = 5\n",
    "        self.similarity_threshold = 0.7\n",
    "\n",
    "    def generate_community_summary(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Generate a summary for the community.\n",
    "\n",
    "        Args:\n",
    "            text (str): Text to summarize.\n",
    "\n",
    "        Returns:\n",
    "            str: Summary of the text.\n",
    "        \"\"\"\n",
    "        messages = [\n",
    "            ChatMessage(\n",
    "                role=\"system\",\n",
    "                content=(\n",
    "                    \"Analyze the following relationships and generate a summary focused on \"\n",
    "                    \"recommendation patterns. Include key features that drive recommendations, \"\n",
    "                    \"common preferences, and relationship strengths. Highlight any clusters \"\n",
    "                    \"or patterns that could be useful for making recommendations.\"\n",
    "                ),\n",
    "            ),\n",
    "            ChatMessage(role=\"user\", content=text),\n",
    "        ]\n",
    "        response = Settings.llm.chat(messages)\n",
    "        clean_reponse = re.sub(r\"^assistant:\\s*\", \"\", str(response)).strip()\n",
    "\n",
    "        return clean_reponse\n",
    "\n",
    "    def build_recommendation_communities(self) -> None:\n",
    "        \"\"\"\n",
    "        Build communities optimized for recommendations.\n",
    "        \"\"\"\n",
    "        graph = self._create_weighted_graph()\n",
    "        community_hierarchical_clusters = hierarchical_leiden(\n",
    "            graph, max_cluster_size=self.max_cluster_size, resolution=1.0\n",
    "        )\n",
    "        self.entity_info, community_info = self._collect_community_info(\n",
    "            graph=graph, clusters=community_hierarchical_clusters\n",
    "        )\n",
    "        self._summarize_communities(community_info=community_info)\n",
    "\n",
    "    def _create_weighted_graph(self) -> nx.Graph:\n",
    "        \"\"\"\n",
    "        Build a NetworkX graph from the graph store.\n",
    "\n",
    "        Returns:\n",
    "            nx.Graph: A NetworkX graph.\n",
    "        \"\"\"\n",
    "        nx_graph = nx.Graph()\n",
    "        triplets = self.get_triplets()\n",
    "\n",
    "        for entity1, relation, entity2 in triplets:\n",
    "            weight = relation.properties.get(\"strength\", 0.5)\n",
    "            nx_graph.add_edge(\n",
    "                relation.source_id,\n",
    "                relation.target_id,\n",
    "                weight=weight,\n",
    "                relationship=relation.label,\n",
    "                description=relation.properties[\"description\"],\n",
    "                features=relation.properties.get(\"features\", \"\"),\n",
    "            )\n",
    "\n",
    "        return nx_graph\n",
    "\n",
    "    def _collect_community_info(\n",
    "        self, graph: nx.Graph, clusters: HierarchicalClusters\n",
    "    ) -> Tuple[Dict[str, Any], Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Collects information about the communities.\n",
    "\n",
    "        Args:\n",
    "            graph (nx.Graph): A NetworkX graph.\n",
    "            clusters (HierarchicalClusters): Hierarchical clusters.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Dict[str, Any], Dict[str, Any]]: A tuple containing entity information and community information.\n",
    "        \"\"\"\n",
    "        entity_info = defaultdict(set)\n",
    "        community_info = defaultdict(list)\n",
    "\n",
    "        for item in clusters:\n",
    "            node = item.node\n",
    "            cluster_id = item.cluster\n",
    "\n",
    "            # Update entity info\n",
    "            entity_info[node].add(cluster_id)\n",
    "\n",
    "            for neighbor in graph.neighbors(node):\n",
    "                edge_data = graph.get_edge_data(node, neighbor)\n",
    "                if edge_data:\n",
    "                    detail = f\"{node} -> {neighbor} -> {edge_data['relationship']} -> {edge_data['description']}\"\n",
    "                    community_info[cluster_id].append(detail)\n",
    "\n",
    "        # Convert sets to lists for easier serialization if needed\n",
    "        entity_info = {k: list(v) for k, v in entity_info.items()}\n",
    "\n",
    "        return dict(entity_info), dict(community_info)\n",
    "\n",
    "    def _summarize_communities(self, community_info: Dict[str, Any]) -> None:\n",
    "        \"\"\"\n",
    "        Generate summaries for the communities.\n",
    "\n",
    "        Args:\n",
    "            community_info (Dict[str, Any]): Community information.\n",
    "        \"\"\"\n",
    "        for community_id, details in community_info.items():\n",
    "            details_text = \"\\n\".join(details) + \".\"\n",
    "            self.community_summary[community_id] = self.generate_community_summary(\n",
    "                text=details_text\n",
    "            )\n",
    "\n",
    "    def get_community_summaries(self):\n",
    "        \"\"\"\n",
    "        Get community summaries.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, Any]: Community summaries.\n",
    "        \"\"\"\n",
    "        if not self.community_summary:\n",
    "            self.build_communities()\n",
    "\n",
    "        return self.community_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITIES_GRAPH_REGEXP_PATTERN = (\n",
    "    r\"^(\\w+(?:\\s+\\w+)*)\\s*->\\s*([a-zA-Z\\s]+?)\\s*->\\s*(\\w+(?:\\s+\\w+)*)$\"\n",
    ")\n",
    "\n",
    "ENTITIES_RESPONSE_PATTERN = (\n",
    "    r'\\(\"entity\"\\$\\$\\$\\$\"(.+?)\"\\$\\$\\$\\$\"(.+?)\"\\$\\$\\$\\$\"(.+?)\"\\$\\$\\$\\$\"(.+?)\"\\)'\n",
    ")\n",
    "RELATIONSHIPS_RESPONSE_PATTERN = r'\\(\"relationship\"\\$\\$\\$\\$\"(.+?)\"\\$\\$\\$\\$\"(.+?)\"\\$\\$\\$\\$\"(.+?)\"\\$\\$\\$\\$\"(.+?)\"\\$\\$\\$\\$\"(.+?)\"\\$\\$\\$\\$\"(.+?)\"\\)'\n",
    "\n",
    "TO_BE_CLEANED_RESPONSE = r\"^assistant:\\s*\"\n",
    "\n",
    "RECOMMENDATION_KG_EXTRACT_TMPL = \"\"\"\n",
    "-Goal-\n",
    "Given a text document, identify entities, their attributes, and relationships that are relevant for making recommendations.\n",
    "Extract up to {max_knowledge_triplets} entity-relation triplets focusing on characteristics that influence recommendations.\n",
    "\n",
    "-Steps-\n",
    "1. Identify all entities, focusing on items, users, and categories. For each entity, extract:\n",
    "- entity_name: Name of the entity, capitalized\n",
    "- entity_type: Type (Item, User, Category, Feature, etc.)\n",
    "- entity_description: Detailed description including preferences, characteristics, and attributes relevant for recommendations\n",
    "- entity_attributes: Key features that could influence recommendations (price, genre, style, etc.)\n",
    "Format: (\"entity\"$$$$<entity_name>$$$$<entity_type>$$$$<entity_description>$$$$<entity_attributes>)\n",
    "\n",
    "2. Identify meaningful relationships between entities that could drive recommendations:\n",
    "- source_entity: Source entity name\n",
    "- target_entity: Target entity name\n",
    "- relation: Relationship type (likes, similar_to, belongs_to, recommends, etc.)\n",
    "- relationship_strength: Numerical score (0-1) indicating relationship strength\n",
    "- relationship_description: Detailed explanation of why these entities are related\n",
    "- recommendation_features: Specific features that make this relationship relevant for recommendations\n",
    "\n",
    "Format: (\"relationship\"$$$$<source_entity>$$$$<target_entity>$$$$<relation>$$$$<relationship_strength>$$$$<relationship_description>$$$$<recommendation_features>)\n",
    "\n",
    "3. When finished, output all entities and relationships.\n",
    "\n",
    "-Real Data-\n",
    "######################\n",
    "text: {text}\n",
    "######################\n",
    "output:\"\"\"\n",
    "\n",
    "GRAPH_NETWORK_HTML_FILEPATH = \"assets/graph_network.html\"\n",
    "\n",
    "DATA_FILE_PATH = \"../data/booking.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from typing import Dict\n",
    "from typing import List\n",
    "\n",
    "from llama_index.core import PropertyGraphIndex\n",
    "from llama_index.core.llms import LLM\n",
    "from llama_index.core.query_engine import CustomQueryEngine\n",
    "\n",
    "\n",
    "class RecommendationGraphRAGQueryEngine(CustomQueryEngine):\n",
    "    graph_store: RecommendationGraphStore\n",
    "    index: PropertyGraphIndex\n",
    "    llm: LLM\n",
    "    similarity_top_k: int = 20\n",
    "\n",
    "    def custom_query(self, query_str: str) -> str:\n",
    "        \"\"\"\n",
    "        Custom query to retrieve recommendations using knowledge from the graph.\n",
    "\n",
    "        Args:\n",
    "            query_str (str): Query string.\n",
    "\n",
    "        Returns:\n",
    "            str: Recommendations.\n",
    "        \"\"\"\n",
    "        entities = self.get_entities(\n",
    "            query_str=query_str, similarity_top_k=self.similarity_top_k\n",
    "        )\n",
    "        \n",
    "        print(f\"Entities: {entities}\")\n",
    "\n",
    "        community_ids = self.retrieve_entity_communities(\n",
    "            entity_info=self.graph_store.entity_info, entities=entities\n",
    "        )\n",
    "        \n",
    "        print(f\"Community IDs: {community_ids}\")\n",
    "\n",
    "        community_recommendations = []\n",
    "        for community_id in community_ids:\n",
    "            recommendations = self._generate_community_recommendations(\n",
    "                community_id=community_id, query_str=query_str, entities=entities\n",
    "            )\n",
    "            community_recommendations.append(recommendations)\n",
    "\n",
    "        # Aggregate and rank recommendations\n",
    "        final_recommendations = self._aggregate_recommendations(\n",
    "            community_recommendations=community_recommendations, query_str=query_str\n",
    "        )\n",
    "\n",
    "        return self._format_recommendations(recommendations=final_recommendations)\n",
    "\n",
    "    def get_entities(self, query_str: str, similarity_top_k: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Get entities from the graph.\n",
    "\n",
    "        Args:\n",
    "            query_str (str): Query string.\n",
    "            similarity_top_k (str): Similarity top k.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: List of entities.\n",
    "        \"\"\"\n",
    "        retrieved_nodes = self.index.as_retriever(\n",
    "            similarity_top_k=similarity_top_k\n",
    "        ).retrieve(query_str)\n",
    "\n",
    "        entities = set()\n",
    "        for node in retrieved_nodes:\n",
    "            matches = re.findall(\n",
    "                pattern=ENTITIES_GRAPH_REGEXP_PATTERN,\n",
    "                string=node,\n",
    "                flags=re.MULTILINE | re.IGNORECASE,\n",
    "            )\n",
    "\n",
    "            for match in matches:\n",
    "                subject = match[0]\n",
    "                obj = match[2]\n",
    "                entities.add(subject)\n",
    "                entities.add(obj)\n",
    "\n",
    "        return list(entities)\n",
    "\n",
    "    def retrieve_entity_communities(\n",
    "        self, entity_info: Dict[str, Any], entities: List[str]\n",
    "    ) -> List[str]:\n",
    "        \"\"\"\n",
    "        Retrieve cluster information for given entities, allowing for multiple clusters per entity.\n",
    "\n",
    "        Args:\n",
    "            entity_info (Dict[str, Any]): Entity information.\n",
    "            entities (List[str]): List of entities.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: List of cluster information.\n",
    "        \"\"\"\n",
    "        community_ids = []\n",
    "\n",
    "        for entity in entities:\n",
    "            if entity in entity_info:\n",
    "                community_ids.extend(entity_info[entity])\n",
    "\n",
    "        return list(set(community_ids))\n",
    "\n",
    "    def _generate_community_recommendations(\n",
    "        self, community_id: int, query_str: str, entities: List[str]\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Generate recommendations from a specific community.\n",
    "\n",
    "        Args:\n",
    "            community_id (int): The community ID.\n",
    "            query_str (str): The query string.\n",
    "            entities (List[str]): The entities.\n",
    "\n",
    "        Returns:\n",
    "            str: The recommendations.\n",
    "        \"\"\"\n",
    "        community_summary = self.graph_store.community_summaries.get(community_id, \"\")\n",
    "        entities_str = \", \".join(entities)\n",
    "        messages = [\n",
    "            ChatMessage(\n",
    "                role=\"system\",\n",
    "                content=(\n",
    "                    f\"Given the community information below and the query, generate relevant \"\n",
    "                    f\"recommendations. Focus on items that match the query intent and have \"\n",
    "                    f\"strong relationships within the community.\\n\\n\"\n",
    "                    f\"Community Summary: {community_summary}\\n\"\n",
    "                    f\"Query Entities: {entities_str}\"\n",
    "                ),\n",
    "            ),\n",
    "            ChatMessage(role=\"user\", content=query_str),\n",
    "        ]\n",
    "\n",
    "        final_response = self.llm.chat(messages=messages)\n",
    "        cleaned_final_response = re.sub(\n",
    "            TO_BE_CLEANED_RESPONSE, \"\", str(final_response)\n",
    "        ).strip()\n",
    "        return cleaned_final_response\n",
    "\n",
    "    def _aggregate_recommendations(\n",
    "        self, community_recommendations: List[str], query_str: str\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Aggregate and rank recommendations from different communities.\n",
    "\n",
    "        Args:\n",
    "            community_recommendations (List[str]): The community recommendations.\n",
    "            query_str (str): The query string.\n",
    "\n",
    "        Returns:\n",
    "            str: The aggregated recommendations\n",
    "        \"\"\"\n",
    "        messages = [\n",
    "            ChatMessage(\n",
    "                role=\"system\",\n",
    "                content=(\n",
    "                    \"Combine and prioritize the following recommendations based on \"\n",
    "                    \"relevance to the query, relationship strength, and diversity. \"\n",
    "                    \"Provide a clear explanation for each recommendation.\"\n",
    "                )\n",
    "            ),\n",
    "            ChatMessage(\n",
    "                role=\"user\",\n",
    "                content=(\n",
    "                    f\"Query: {query_str}\\n\\n\"\n",
    "                    f\"Community Recommendations:\\n\"\n",
    "                    f\"{'-' * 40}\\n\"\n",
    "                    + \"\\n\".join(community_recommendations)\n",
    "                )\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        final_response = self.llm.chat(messages=messages)\n",
    "        cleaned_final_response = re.sub(\n",
    "            TO_BE_CLEANED_RESPONSE, \"\", str(final_response)\n",
    "        ).strip()\n",
    "        return cleaned_final_response\n",
    "\n",
    "    def _format_recommendations(self, recommendations: str) -> str:\n",
    "        \"\"\"\n",
    "        Format recommendations for presentation.\n",
    "\n",
    "        Args:\n",
    "            recommendations (str): The recommendations.\n",
    "\n",
    "        Returns:\n",
    "            str: The formatted recommendations.\n",
    "        \"\"\"\n",
    "        messages = [\n",
    "            ChatMessage(\n",
    "                role=\"system\",\n",
    "                content=(\n",
    "                    \"Format the recommendations in a clear, structured way. \"\n",
    "                    \"Include relevant details such as similarity scores, key features, \"\n",
    "                    \"and reasoning for each recommendation.\"\n",
    "                ),\n",
    "            ),\n",
    "            ChatMessage(role=\"user\", content=recommendations),\n",
    "        ]\n",
    "\n",
    "        final_response = self.llm.chat(messages=messages)\n",
    "        cleaned_final_response = re.sub(\n",
    "            TO_BE_CLEANED_RESPONSE, \"\", str(final_response)\n",
    "        ).strip()\n",
    "        return cleaned_final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fn(response_str: str) -> Any:\n",
    "    entities = re.findall(ENTITIES_RESPONSE_PATTERN, response_str)\n",
    "    relationships = re.findall(RELATIONSHIPS_RESPONSE_PATTERN, response_str)\n",
    "    return entities, relationships\n",
    "\n",
    "\n",
    "kg_extractor = RecommendationGraphExtractor(\n",
    "    llm=llm,\n",
    "    extract_prompt=RECOMMENDATION_KG_EXTRACT_TMPL,\n",
    "    max_paths_per_chunk=2,\n",
    "    parse_fn=parse_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_store = RecommendationGraphStore(\n",
    "    username=\"neo4j\", password=\"password\", url=\"bolt://localhost:7687\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text: 100%|██████████| 34/34 [00:13<00:00,  2.53it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.93s/it]\n",
      "Generating embeddings: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import PropertyGraphIndex\n",
    "\n",
    "index = PropertyGraphIndex(\n",
    "    nodes=nodes,\n",
    "    kg_extractors=[kg_extractor],\n",
    "    property_graph_store=graph_store,\n",
    "    show_progress=True,\n",
    "    embed_model=embed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = RecommendationGraphRAGQueryEngine(\n",
    "    graph_store=index.property_graph_store,\n",
    "    llm=llm,\n",
    "    index=index,\n",
    "    similarity_top_k=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities: []\n",
      "Community IDs: []\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Recommendations for Hotels with Views of the Eiffel Tower:**\n",
       "\n",
       "1. **Hotel Pullman Paris Tour Eiffel**\n",
       "   - Similarity Score: High\n",
       "   - Key Features: Stunning views of the Eiffel Tower, proximity to the landmark\n",
       "   - Reasoning: Known for its exceptional views and convenient location near the Eiffel Tower, ideal for guests seeking a good view.\n",
       "\n",
       "2. **Shangri-La Hotel Paris**\n",
       "   - Similarity Score: High\n",
       "   - Key Features: Luxurious accommodations, best views of the Eiffel Tower\n",
       "   - Reasoning: Offers some of the best views of the Eiffel Tower from rooms and suites, providing a memorable and picturesque experience.\n",
       "\n",
       "3. **Le Metropolitan, a Tribute Portfolio Hotel**\n",
       "   - Similarity Score: Medium\n",
       "   - Key Features: Views of the Eiffel Tower, convenient location\n",
       "   - Reasoning: Located near the Eiffel Tower, offering rooms with views of the iconic landmark for a pleasant stay with convenience.\n",
       "\n",
       "4. **Mercure Paris Centre Eiffel Tower Hotel**\n",
       "   - Similarity Score: Medium\n",
       "   - Key Features: Close proximity to the Eiffel Tower, rooms with tower views\n",
       "   - Reasoning: Situated near the Eiffel Tower, providing easy access to the attraction and memorable views for guests.\n",
       "\n",
       "5. **Hotel Plaza Athenee**\n",
       "   - Similarity Score: Low\n",
       "   - Key Features: Luxury accommodations, stunning Eiffel Tower views\n",
       "   - Reasoning: Offers upscale accommodations with unique views of the Eiffel Tower from select rooms, providing a luxurious experience for guests."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"Suggestions for a hotel in Paris with a good view and close to the Eiffel Tower.\"\n",
    ")\n",
    "display(Markdown(f\"{response.response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
